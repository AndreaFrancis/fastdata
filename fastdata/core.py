"""Fill in a module description here"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_core.ipynb.

# %% auto 0
__all__ = ['FastData']

# %% ../nbs/00_core.ipynb 3
import concurrent.futures
from pydantic import BaseModel
import instructor
import anthropic
from tqdm import tqdm
from ratelimit import limits, sleep_and_retry

# %% ../nbs/00_core.ipynb 4
class FastData:
    def __init__(self, api_key: str | None = None, calls: int = 100, period: int = 60):
        self.client = instructor.from_anthropic(anthropic.Anthropic(api_key=api_key))
        self.set_rate_limit(calls, period)

    def set_rate_limit(self, calls: int, period: int):
        """Set a new rate limit."""
        @sleep_and_retry
        @limits(calls=calls, period=period)
        def rate_limited_call(model: str, messages: list[dict], response_model: BaseModel):
            return self.client.chat.completions.create(
                model=model,
                max_tokens=4096,
                max_retries=1,
                messages=messages,
                response_model=response_model,
            )
        
        self._rate_limited_call = rate_limited_call

    def generate(self, 
                 prompt_template: str, 
                 inputs: list[dict], 
                 response_model: BaseModel, 
                 model: str = "claude-3-haiku-20240307",
                 max_workers: int = 64) -> list[dict]:
        
        def process_input(input_data):
            try:
                prompt = prompt_template.format(**input_data)
                response = self._rate_limited_call(
                    model=model,
                    messages=[{"role": "user", "content": prompt}],
                    response_model=response_model,
                )
                return response.dict()
            except Exception as e:
                print(f"Error processing input: {e}")
                return None

        results = []
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [executor.submit(process_input, input_data) for input_data in inputs]
            for future in tqdm(concurrent.futures.as_completed(futures), total=len(inputs)):
                result = future.result()
                if result:
                    results.append(result)
        
        return results
